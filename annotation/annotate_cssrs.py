#!/usr/bin/env python3
"""
ä½¿ç”¨ Ollama æ¨™è¨»è¨Šæ¯çš„å¤šå€‹ç¶­åº¦ï¼šC-SSRSã€Ekman æƒ…ç·’ã€DASS-21ã€Russell Circumplex
"""

import csv
import json
import requests
import time
from pathlib import Path
from typing import Dict, List

# é…ç½®
OLLAMA_API = "http://localhost:11434/api/generate"
MODEL = "gpt-oss:20b"
INPUT_CSV = "../conversation.csv"
OUTPUT_CSV = "conversation_annotated.csv"

# ============================================================================
# PROMPT 1: C-SSRS è‡ªæ®ºé¢¨éšªè©•ä¼° (åƒ… HUMAN)
# ============================================================================
CSSRS_PROMPT = """ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è‡¨åºŠå¿ƒç†å­¸å®¶ï¼Œç²¾é€šè‡ªæ®ºé¢¨éšªè©•ä¼°ã€‚è«‹ä½¿ç”¨ Columbia-Suicide Severity Rating Scale (C-SSRS) å°ç£ç‰ˆæœ¬æ¨™è¨»ä»¥ä¸‹è¨Šæ¯çš„è‡ªæ®ºé¢¨éšªç­‰ç´šã€‚

**C-SSRS å±æ©Ÿè©•ä¼°åˆ†æ•¸å°ç…§è¡¨**ï¼ˆåƒè€ƒè¼”ä»å¤§å­¸å­¸ç”Ÿè¼”å°ä¸­å¿ƒç‰ˆæœ¬ï¼‰ï¼š

0 åˆ† - ç„¡è‡ªæ®ºæ„å¿µï¼ˆç„¡å±æ©Ÿç·šç´¢ï¼‰
   - ç„¡ä»»ä½•è‡ªæ®ºæƒ³æ³•
   - ç„¡å±æ©Ÿç·šç´¢

1 åˆ† - æ¶ˆæ¥µè‡ªæ®ºæ„å¿µï¼ˆä½åº¦å±æ©Ÿï¼‰
   - å¸Œæœ›æ­»äº¡ä½†ç„¡ç©æ¥µè‡ªæ®ºè¨ˆç•«
   - å°‘æ•¸ç·šç´¢é¡¯ç¤ºï¼Œå±æ©Ÿç¨‹åº¦å°ä¸”ç„¡ç«‹å³æ€§
   - ä»åœ¨å€‹æ¡ˆè‡ªæˆ‘ç®¡ç†ç¯„åœï¼ˆä¿è­·å› å­ > å±éšªå› å­ï¼‰
   - ä¾‹ï¼šã€Œå¸Œæœ›ç¡è‘—å°±ä¸è¦é†’ä¾†ã€

2 åˆ† - ç©æ¥µè‡ªæ®ºæ„å¿µ / æœ‰æ–¹æ³•çš„ç©æ¥µè‡ªæ®ºæ„å¿µï¼ˆä½~ä¸­åº¦å±æ©Ÿï¼‰
   - æœ‰æƒ³æ­»çš„å¿µé ­ï¼Œå¯èƒ½æƒ³åˆ°å…·é«”æ–¹æ³•
   - ç·šç´¢é¡¯ç¤ºæœ‰æ½›åœ¨å±æ©Ÿå¯èƒ½ï¼Œå¯ä»‹å…¥é é˜²ï¼ˆå¯æ§åˆ¶ï¼‰
   - ä¿è­·å› å­ > å±éšªå› å­
   - ä¾‹ï¼šã€Œæˆ‘æƒ³æ­»ã€ã€ã€Œæƒ³éè·³æµ·ä½†ä¸æœƒåšã€

3 åˆ† - æœ‰æ„åœ–çš„ç©æ¥µè‡ªæ®ºæ„å¿µ / æœ‰è¨ˆç•«å’Œæ„åœ–ï¼ˆä¸­åº¦å±æ©Ÿï¼‰
   - æœ‰åŸ·è¡Œæ„åœ–ï¼Œå¯èƒ½æœ‰è¨ˆç•«
   - ç·šç´¢é¡¯ç¤ºæœ‰æ½›åœ¨å±æ©Ÿå¯èƒ½ï¼Œéœ€ä»‹å…¥é é˜²ï¼ˆä¸å¯æ§åˆ¶ï¼‰
   - å±éšªå› å­ > ä¿è­·å› å­
   - ä¾‹ï¼šã€Œæˆ‘çœŸçš„æƒ³æ­»ã€ä¸”æœ‰æ–¹æ³•æˆ–è¨ˆç•«

4 åˆ† - æº–å‚™è¡Œç‚º / æ”¾æ£„æˆ–è¢«ä¸­æ–·çš„å˜—è©¦ï¼ˆé«˜åº¦å±æ©Ÿï¼‰
   - æœ‰æº–å‚™è¡Œç‚ºï¼ˆå¯«éºæ›¸ã€æ”¶é›†å·¥å…·ï¼‰
   - æˆ–æ›¾å˜—è©¦ä½†æ”¾æ£„æˆ–è¢«ä¸­æ–·
   - å±æ©Ÿå¯èƒ½æ€§æ¥µé«˜ï¼ŒçŸ­æœŸå…§å¯èƒ½ç”¢ç”Ÿå±æ©Ÿ
   - æœ‰ç«‹å³ä»‹å…¥ä¹‹å¿…è¦
   - ä¾‹ï¼šã€Œé–‹å§‹å¯«éºæ›¸ã€ã€ã€Œæ›¾ç¶“æº–å‚™å¥½ä½†æ²’åšã€

5 åˆ† - å¯¦éš›è‡ªæ®ºå˜—è©¦ / æ­£è™•å±æ©Ÿä¸­ï¼ˆé«˜åº¦å±æ©Ÿï¼‰
   - æœ‰å¯¦éš›è‡ªæ®ºå˜—è©¦
   - æˆ–ç›®å‰æ­£è™•æ–¼å±æ©Ÿç•¶ä¸­
   - æœ‰ç«‹å³ä»‹å…¥ä¹‹å¿…è¦
   - ä¾‹ï¼šã€Œç¾åœ¨å°±è¦å»åšã€ã€ã€Œå·²ç¶“æº–å‚™å¥½ä»Šæ™šåŸ·è¡Œã€

**ç‰¹åˆ¥æ³¨æ„**ï¼š
- ã€Œåˆ—éºæ›¸ã€ã€ã€Œå¯«éºæ›¸ã€ã€ã€Œç˜‹ç‹‚å¯«éºæ›¸ã€â†’ 4 åˆ†ï¼ˆæº–å‚™è¡Œç‚ºï¼‰
- åœ¨æ½›åœ¨è‡ªæ®ºåœ°é»ï¼ˆå¤–æœ¨å±±ï¼‰ä½†èªªã€Œæ²’æœ‰å‹•åŠ›å»æ­»ã€â†’ 2 åˆ†ï¼ˆæœ‰æ–¹æ³•ä½†å¯æ§åˆ¶ï¼‰
- ã€Œå‰›æ‰æƒ³éã€ä¸”ç›®å‰å·²ç·©è§£ â†’ 1-2 åˆ†ï¼ˆè¦–æƒ…æ³ï¼‰
- æ­£å¿µè§€å¯Ÿï¼ˆã€Œçœ‹è‘—å¿µé ­ã€ï¼‰â†’ æ¨™è¨»ç‚ºä¿è­·å› å­
- ã€Œå¯ä»¥å»æ­»ã€ä½†æœ‰æ¢ä»¶è¨­å®šï¼ˆå¦‚ã€Œç­‰ç—…å¥½äº†ã€ï¼‰â†’ 2-3 åˆ†
- è©•ä¼°æ™‚è€ƒæ…®ï¼šä¿è­·å› å­ vs å±éšªå› å­çš„å¹³è¡¡

**è¨Šæ¯å…§å®¹**ï¼š
{message}

**æ¨™è¨»ç¯„ä¾‹**ï¼š

ç¯„ä¾‹ 1 - è¨Šæ¯ï¼šã€Œæˆ‘æƒ³æ­»ï¼Œä½†åˆä¸æƒ³æ­»ã€
{{
  "score": 2,
  "keywords": ["æƒ³æ­»", "åˆä¸æƒ³æ­»"],
  "protective_factors": ["åˆä¸æƒ³æ­»"],
  "risk_factors": ["æƒ³æ­»"]
}}

ç¯„ä¾‹ 2 - è¨Šæ¯ï¼šã€Œä»Šå¤©å¤©æ°£ä¸éŒ¯ï¼Œå»æ•£æ­¥äº†ã€
{{
  "score": 0,
  "keywords": ["å¤©æ°£ä¸éŒ¯", "æ•£æ­¥"],
  "protective_factors": ["å»æ•£æ­¥äº†"],
  "risk_factors": []
}}

ç¯„ä¾‹ 3 - è¨Šæ¯ï¼šã€Œå‰›æ‰åœ¨åºŠä¸Šä¸€ç›´æƒ³è‡ªæ®ºï¼Œå¥½æƒ³è§£è„«ã€
{{
  "score": 3,
  "keywords": ["åœ¨åºŠä¸Š", "ä¸€ç›´æƒ³è‡ªæ®º", "å¥½æƒ³è§£è„«"],
  "protective_factors": [],
  "risk_factors": ["ä¸€ç›´æƒ³è‡ªæ®º", "å¥½æƒ³è§£è„«"]
}}

ç¯„ä¾‹ 4 - è¨Šæ¯ï¼šã€Œæˆ‘æŠŠéºæ›¸å¯«å¥½äº†ã€
{{
  "score": 4,
  "keywords": ["éºæ›¸å¯«å¥½äº†"],
  "protective_factors": [],
  "risk_factors": ["éºæ›¸å¯«å¥½äº†"]
}}

**è«‹ä»¥ JSON æ ¼å¼è¼¸å‡º**ï¼ˆä¸è¦å…¶ä»–æ–‡å­—ï¼Œåªè¦ JSONï¼‰ï¼š
{{
  "score": [0-5],
  "keywords": ["é—œéµè©1", "é—œéµè©2",...],
  "protective_factors": ["ä¿è­·å› å­1",...] æˆ– [],
  "risk_factors": ["å±éšªå› å­1",...] æˆ– []
}}
"""


def call_ollama(prompt: str, model: str = MODEL) -> dict:
    """å‘¼å« Ollama API"""
    payload = {
        "model": model,
        "prompt": prompt,
        "stream": False,
        "temperature": 0.0  # Temperature = 0 ç¢ºä¿å®Œå…¨ç¢ºå®šæ€§å’Œå¯é‡è¤‡æ€§
        # NOTE: gpt-oss:20b ä¸æ”¯æ´ "format": "json"ï¼Œç§»é™¤æ­¤åƒæ•¸
    }
    
    try:
        response = requests.post(OLLAMA_API, json=payload, timeout=120)
        response.raise_for_status()
        result = response.json()
        
        # è§£æ JSON å›æ‡‰
        response_text = result.get("response", "")
        return json.loads(response_text)
    
    except requests.exceptions.RequestException as e:
        print(f"âŒ Ollama API éŒ¯èª¤: {e}")
        return None
    except json.JSONDecodeError as e:
        print(f"âŒ JSON è§£æéŒ¯èª¤: {e}")
        print(f"åŸå§‹å›æ‡‰: {response_text}")
        return None


def annotate_message(message_id: int, speaker: str, message: str, day: int) -> dict:
    """æ¨™è¨»å–®ä¸€è¨Šæ¯"""
    
    # åªæ¨™è¨» HUMAN è¨Šæ¯
    if speaker != "HUMAN":
        return {
            "message_id": message_id,
            "speaker": speaker,
            "message": message,
            "day": day,
            "cssrs_score": None,
            "rationale": "åƒ…æ¨™è¨» HUMAN è¨Šæ¯",
            "keywords": [],
            "protective_factors": [],
            "risk_factors": []
        }
    
    print(f"\nğŸ“ æ¨™è¨»è¨Šæ¯ #{message_id}...")
    print(f"å…§å®¹: {message[:80]}..." if len(message) > 80 else f"å…§å®¹: {message}")
    
    # æº–å‚™ Prompt
    prompt = CSSRS_PROMPT.format(message=message)
    
    # å‘¼å« LLM
    result = call_ollama(prompt)
    
    if result is None:
        print(f"âš ï¸  æ¨™è¨»å¤±æ•—ï¼Œä¿ç•™ None")
        return {
            "message_id": message_id,
            "speaker": speaker,
            "message": message,
            "day": day,
            "cssrs_score": None,
            "rationale": "æ¨™è¨»å¤±æ•—",
            "keywords": "",
            "protective_factors": "",
            "risk_factors": ""
        }
    
    score = result.get("score", 0)
    print(f"âœ… C-SSRS åˆ†æ•¸: {score}")
    
    return {
        "message_id": message_id,
        "speaker": speaker,
        "message": message,
        "day": day,
        "cssrs_score": score,
        "rationale": result.get("rationale", ""),
        "keywords": ",".join(result.get("keywords", [])),
        "protective_factors": ",".join(result.get("protective_factors", [])),
        "risk_factors": ",".join(result.get("risk_factors", []))
    }


def main():
    """ä¸»ç¨‹å¼"""
    print("=" * 60)
    print("ğŸ¯ C-SSRS è‡ªæ®ºé¢¨éšªæ¨™è¨»è…³æœ¬")
    print("=" * 60)
    print(f"æ¨¡å‹: {MODEL}")
    print(f"è¼¸å…¥: {INPUT_CSV}")
    print(f"è¼¸å‡º: {OUTPUT_CSV}")
    print("=" * 60)
    
    # æª¢æŸ¥ Ollama æ˜¯å¦é‹è¡Œ
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        response.raise_for_status()
        print("âœ… Ollama æ­£åœ¨é‹è¡Œ")
    except:
        print("âŒ éŒ¯èª¤ï¼šOllama æœªé‹è¡Œï¼Œè«‹å…ˆåŸ·è¡Œ 'ollama serve'")
        return
    
    # è®€å– CSV
    input_path = Path(__file__).parent / INPUT_CSV
    if not input_path.exists():
        print(f"âŒ æ‰¾ä¸åˆ°è¼¸å…¥æª”æ¡ˆ: {input_path}")
        return
    
    print(f"\nğŸ“‚ è®€å– {input_path}...")
    
    conversations = []
    with open(input_path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            conversations.append({
                "message_id": int(row["åºè™Ÿ"]),
                "speaker": row["èªªè©±è€…"],
                "message": row["è¨Šæ¯å…§å®¹"],
                "day": int(row["Day"])
            })
    
    print(f"âœ… å…±è®€å– {len(conversations)} æ¢è¨Šæ¯")
    
    human_count = sum(1 for c in conversations if c["speaker"] == "HUMAN")
    print(f"ğŸ“Š å…¶ä¸­ HUMAN è¨Šæ¯: {human_count} æ¢")
    
    # ç¢ºèªæ˜¯å¦ç¹¼çºŒ
    print(f"\nâš ï¸  å³å°‡æ¨™è¨» {human_count} æ¢ HUMAN è¨Šæ¯")
    print(f"é ä¼°æ™‚é–“: ç´„ {human_count * 10 // 60} åˆ†é˜ï¼ˆæ¯æ¢ç´„ 10 ç§’ï¼‰")
    
    # é–‹å§‹æ¨™è¨»
    results = []
    start_time = time.time()
    
    for i, conv in enumerate(conversations, 1):
        print(f"\né€²åº¦: {i}/{len(conversations)}")
        
        result = annotate_message(
            conv["message_id"],
            conv["speaker"],
            conv["message"],
            conv["day"]
        )
        results.append(result)
        
        # æ¯ 10 æ¢è¨Šæ¯ä¼‘æ¯ 1 ç§’ï¼Œé¿å…éè¼‰
        if i % 10 == 0:
            print("ğŸ’¤ ä¼‘æ¯ 1 ç§’...")
            time.sleep(1)
    
    # å¯«å…¥ CSV
    output_path = Path(__file__).parent / OUTPUT_CSV
    print(f"\nğŸ’¾ å¯«å…¥çµæœåˆ° {output_path}...")
    
    with open(output_path, 'w', encoding='utf-8', newline='') as f:
        fieldnames = [
            "message_id", "speaker", "message", "day",
            "cssrs_score", "rationale", "keywords", "protective_factors", "risk_factors"
        ]
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(results)
    
    # çµ±è¨ˆ
    elapsed = time.time() - start_time
    human_results = [r for r in results if r["speaker"] == "HUMAN"]
    scores = [r["cssrs_score"] for r in human_results if r["cssrs_score"] is not None]
    
    print("\n" + "=" * 60)
    print("âœ… æ¨™è¨»å®Œæˆï¼")
    print("=" * 60)
    print(f"ç¸½è¨Šæ¯æ•¸: {len(results)}")
    print(f"HUMAN è¨Šæ¯: {len(human_results)}")
    print(f"æ¨™è¨»æˆåŠŸ: {len(scores)}")
    print(f"è€—æ™‚: {elapsed:.1f} ç§’ ({elapsed/60:.1f} åˆ†é˜)")
    print("\nğŸ“Š C-SSRS åˆ†æ•¸åˆ†å¸ƒ:")
    for score in range(6):
        count = scores.count(score)
        if count > 0:
            bar = "â–ˆ" * count
            print(f"  {score} åˆ†: {count:2d} æ¢ {bar}")
    
    if scores:
        avg_score = sum(scores) / len(scores)
        max_score = max(scores)
        high_risk_count = sum(1 for s in scores if s >= 4)
        
        print(f"\nå¹³å‡åˆ†æ•¸: {avg_score:.2f}")
        print(f"æœ€é«˜åˆ†æ•¸: {max_score}")
        print(f"é«˜é¢¨éšª (â‰¥4): {high_risk_count} æ¢")
    
    print(f"\nğŸ’¾ çµæœå·²å„²å­˜è‡³: {output_path}")
    print("\nä¸‹ä¸€æ­¥ï¼š")
    print("1. æª¢æŸ¥ conversation_cssrs.csv")
    print("2. äººå·¥è¤‡æŸ¥é«˜é¢¨éšªè¨Šæ¯ (4-5 åˆ†)")
    print("3. åŸ·è¡Œè¦–è¦ºåŒ–è…³æœ¬")


if __name__ == "__main__":
    main()
